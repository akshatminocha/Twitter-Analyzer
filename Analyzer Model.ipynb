{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to create new columns from the description columns\n",
    "interests = ['python', 'machine learning', 'deep learning', 'engineer','data science','artificial intelligence', 'nlp','cs','computers','follow','followback']\n",
    "def new_column(string):\n",
    "    df[string] = np.where(df['description'].str.lower().str.contains(string)==True,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Twitter_MOST_New.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling function to create new columns\n",
    "for i in interests:\n",
    "    new_column(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping irrelevant attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['utc_offset'],axis=1,inplace=True)\n",
    "df.url_count.fillna(0,inplace=True) #url count for users is 0 hence it is showing a null value, thats why replacing it with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have extracted information from the description columns hence not required.\n",
    "df.drop(['description'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns have either large number of unique Values or a single value for all the obeservations. \n",
    "df.drop(['username','user_id','protected'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First converting them to 'object' type\n",
    "df['geo_enabled'] = df['geo_enabled'].astype(str)\n",
    "df['veified'] = df['veified'].astype(str)\n",
    "df['contributors_enabled'] = df['contributors_enabled'].astype(str)\n",
    "df['translation_enabled'] = df['translation_enabled'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping True with 1 and False with 0\n",
    "df.geo_enabled.replace(['True','False'],[1, 0],inplace=True)\n",
    "df.veified.replace(['True','False'],[1, 0],inplace=True)\n",
    "df.contributors_enabled.replace(['True','False'],[1, 0],inplace=True)\n",
    "df.translation_enabled.replace(['True','False'],[1, 0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['user_follows_me'],axis=1)\n",
    "y = df['user_follows_me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.30,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_following = X[X.user_follows_me==0]\n",
    "following = X[X.user_follows_me==1]\n",
    "\n",
    "# upsample minority\n",
    "following_upsampled = resample(following,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_following), # match number in majority class\n",
    "                          random_state=42) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_following, following_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "##upsampled.user_follows_me.value_counts()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = upsampled.drop(['user_follows_me'],axis=1)\n",
    "y_train = upsampled.loc[:,['user_follows_me']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier()\n",
    "XGB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_XGB = XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79       504\n",
      "           1       0.21      0.47      0.29        81\n",
      "\n",
      "    accuracy                           0.68       585\n",
      "   macro avg       0.55      0.59      0.54       585\n",
      "weighted avg       0.80      0.68      0.72       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions_XGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(XGB, open('final_prediction.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
